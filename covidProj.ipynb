{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79826f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab363c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "pathFull = \"/Users/Avaneesh/Library/Mobile Documents/com~apple~CloudDocs/Georgia Tech/AI:ML/COVID-19_Radiography_Dataset/\"\n",
    "# Set base path to dataset\n",
    "\n",
    "pathCOV = pathFull + \"COVID/images\"\n",
    "pathNorm = pathFull + \"Normal/images\"\n",
    "cntCOVimg = len(os.listdir(pathCOV))\n",
    "cntNormimg = len(os.listdir(pathNorm))\n",
    "# Get image directories and count images for each class\n",
    "\n",
    "COVimg = []\n",
    "COVlab = []\n",
    "COVname = []\n",
    "for x in range(1,cntCOVimg + 1):\n",
    "    imgName1 = \"COVID-\" + str(x) + \".png\"\n",
    "    tempPath1 = pathCOV + \"/\" + imgName1\n",
    "    img1 = cv2.imread(tempPath1)\n",
    "    img1 = np.float32(cv2.resize(img1, (100,100))) / 255.0\n",
    "    COVimg.append(img1)\n",
    "    COVlab.append(1)\n",
    "    COVname.append(imgName1)\n",
    "# Load, resize, and normalize COVID images; assign label 1\n",
    "\n",
    "df = pd.DataFrame({\"Image\" : COVimg,\"Label\" : COVlab, \"Image Name\" : COVname})\n",
    "# Create DataFrame for COVID images\n",
    "\n",
    "Normimg = []\n",
    "Normlab = []\n",
    "Normname = []\n",
    "\n",
    "rndm = list(range(1,cntNormimg+1))\n",
    "random.shuffle(rndm)\n",
    "newidx = rndm[:cntCOVimg]\n",
    "for x in newidx:\n",
    "    imgName2 = \"Normal-\" + str(x) + \".png\"\n",
    "    tempPath2 = pathNorm + \"/\" + imgName2\n",
    "    img2 = cv2.imread(tempPath2)\n",
    "    img2 = np.float32(cv2.resize(img2, (100,100))) / 255.0\n",
    "    Normimg.append(img2)\n",
    "    Normlab.append(0)\n",
    "    Normname.append(imgName2)\n",
    "# Randomly select and process Normal images to balance dataset; assign label 0\n",
    "\n",
    "df2 = pd.DataFrame({\"Image\" : Normimg,\"Label\" : Normlab, \"Image Name\" : Normname})\n",
    "# Create DataFrame for Normal images\n",
    "\n",
    "data = pd.concat([df, df2], axis=0,ignore_index=False)\n",
    "data = data.sample(frac=1,replace=True, ignore_index=True)\n",
    "# Combine and shuffle both classes\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"Image\"],data[\"Label\"], test_size=.25)\n",
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "COVmodel = Sequential([\n",
    "    Input(shape=(100,100,3)),  # Input layer for 100x100 RGB images\n",
    "    Conv2D(32, 3, activation='relu'),  # First convolutional layer\n",
    "    MaxPooling2D(),                   # First pooling layer\n",
    "    Conv2D(16, 3, activation='relu'), # Second convolutional layer\n",
    "    MaxPooling2D(),                   # Second pooling layer\n",
    "    Conv2D(16, 3, activation='relu'), # Third convolutional layer\n",
    "    MaxPooling2D(),                   # Third pooling layer\n",
    "    Flatten(),                        # Flatten feature maps\n",
    "    Dense(512, activation='relu'),    # Dense layer with 512 units\n",
    "    Dropout(0.5),                     # Dropout for regularization\n",
    "    Dense(256, activation='relu'),    # Dense layer with 256 units\n",
    "    Dropout(0.5),                     # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')    # Output layer for binary classification\n",
    "])\n",
    "\n",
    "COVmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compilation and Training\n",
    "COVmodel.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "# Compile model with Adam optimizer and binary crossentropy loss\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "# Set up early stopping to prevent overfitting\n",
    "\n",
    "x_train = np.array([img for img in x_train])\n",
    "x_test = np.array([img for img in x_test])\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "# Convert data to numpy arrays\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "# Print shapes for verification\n",
    "\n",
    "COVmodel.fit(x_train, y_train,epochs=25,validation_data=(x_test, y_test), callbacks=early_stopping)\n",
    "# Train the model with early stopping and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "plt.plot(COVmodel.history.history['accuracy'], label = 'train accuracy')\n",
    "plt.plot(COVmodel.history.history['val_accuracy'],label = 'test accuracy')\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Percent Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot training and validation accuracy over epochs\n",
    "\n",
    "plt.plot(COVmodel.history.history['loss'], label = 'train loss')\n",
    "plt.plot(COVmodel.history.history['val_loss'],label = 'test_loss')\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Percent Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot training and validation loss over epochs\n",
    "\n",
    "y_pred = (COVmodel.predict(x_test) > 0.5).astype(int).flatten()\n",
    "# Predict on test set and threshold to get binary labels\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Compute confusion matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"COVID\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "# Display confusion matrix as a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM Visualization\n",
    "\n",
    "def get_img_array(img):\n",
    "    # Ensure image is float32 and shape (1, 100, 100, 3)\n",
    "    arr = np.expand_dims(img, axis=0)\n",
    "    return arr\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    # Compute the gradient of the top predicted class for the input image\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    # Get gradients of the class output value with respect to the feature map\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def plot_gradcam_for_img(img, model, last_conv_layer_name):\n",
    "    \n",
    "    # Prepare image for model\n",
    "    img_array = get_img_array(img)\n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    # Prepare images for display\n",
    "    img_disp = np.uint8(255 * img)\n",
    "    heatmap_resized = cv2.resize(heatmap, (img_disp.shape[1], img_disp.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img_disp, 0.6, heatmap_colored, 0.4, 0)\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original X-ray\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Grad-CAM Heatmap\")\n",
    "    plt.imshow(heatmap, cmap='jet')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Superimposed\")\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
