{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79826f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab363c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "pathFull = \"/Users/Avaneesh/Library/Mobile Documents/com~apple~CloudDocs/Georgia Tech/AI:ML/COVID-19_Radiography_Dataset/\"\n",
    "# Set base path to dataset\n",
    "\n",
    "pathCOV = pathFull + \"COVID/images\"\n",
    "pathNorm = pathFull + \"Normal/images\"\n",
    "cntCOVimg = len(os.listdir(pathCOV))\n",
    "cntNormimg = len(os.listdir(pathNorm))\n",
    "# Get image directories and count images for each class\n",
    "\n",
    "COVimg = []\n",
    "COVlab = []\n",
    "COVname = []\n",
    "for x in range(1,cntCOVimg + 1):\n",
    "    imgName1 = \"COVID-\" + str(x) + \".png\"\n",
    "    tempPath1 = pathCOV + \"/\" + imgName1\n",
    "    img1 = cv2.imread(tempPath1)\n",
    "    img1 = np.float32(cv2.resize(img1, (100,100))) / 255.0\n",
    "    COVimg.append(img1)\n",
    "    COVlab.append(1)\n",
    "    COVname.append(imgName1)\n",
    "# Load, resize, and normalize COVID images; assign label 1\n",
    "\n",
    "df = pd.DataFrame({\"Image\" : COVimg,\"Label\" : COVlab, \"Image Name\" : COVname})\n",
    "# Create DataFrame for COVID images\n",
    "\n",
    "Normimg = []\n",
    "Normlab = []\n",
    "Normname = []\n",
    "\n",
    "rndm = list(range(1,cntNormimg+1))\n",
    "random.shuffle(rndm)\n",
    "newidx = rndm[:cntCOVimg]\n",
    "for x in newidx:\n",
    "    imgName2 = \"Normal-\" + str(x) + \".png\"\n",
    "    tempPath2 = pathNorm + \"/\" + imgName2\n",
    "    img2 = cv2.imread(tempPath2)\n",
    "    img2 = np.float32(cv2.resize(img2, (100,100))) / 255.0\n",
    "    Normimg.append(img2)\n",
    "    Normlab.append(0)\n",
    "    Normname.append(imgName2)\n",
    "# Randomly select and process Normal images to balance dataset; assign label 0\n",
    "\n",
    "df2 = pd.DataFrame({\"Image\" : Normimg,\"Label\" : Normlab, \"Image Name\" : Normname})\n",
    "# Create DataFrame for Normal images\n",
    "\n",
    "data = pd.concat([df, df2], axis=0,ignore_index=False)\n",
    "data = data.sample(frac=1,replace=True, ignore_index=True)\n",
    "# Combine and shuffle both classes\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"Image\"],data[\"Label\"], test_size=.25)\n",
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "COVmodel = Sequential([\n",
    "    Input(shape=(100,100,3)),  # Input layer for 100x100 RGB images\n",
    "    Conv2D(32, 3, activation='relu'),  # First convolutional layer\n",
    "    MaxPooling2D(),                   # First pooling layer\n",
    "    Conv2D(16, 3, activation='relu'), # Second convolutional layer\n",
    "    MaxPooling2D(),                   # Second pooling layer\n",
    "    Conv2D(16, 3, activation='relu'), # Third convolutional layer\n",
    "    MaxPooling2D(),                   # Third pooling layer\n",
    "    Flatten(),                        # Flatten feature maps\n",
    "    Dense(512, activation='relu'),    # Dense layer with 512 units\n",
    "    Dropout(0.5),                     # Dropout for regularization\n",
    "    Dense(256, activation='relu'),    # Dense layer with 256 units\n",
    "    Dropout(0.5),                     # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')    # Output layer for binary classification\n",
    "])\n",
    "\n",
    "COVmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compilation and Training\n",
    "COVmodel.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "# Compile model with Adam optimizer and binary crossentropy loss\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "# Set up early stopping to prevent overfitting\n",
    "\n",
    "x_train = np.array([img for img in x_train])\n",
    "x_test = np.array([img for img in x_test])\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "# Convert data to numpy arrays\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "# Print shapes for verification\n",
    "\n",
    "COVmodel.fit(x_train, y_train,epochs=25,validation_data=(x_test, y_test), callbacks=early_stopping)\n",
    "# Train the model with early stopping and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "plt.plot(COVmodel.history.history['accuracy'], label = 'train accuracy')\n",
    "plt.plot(COVmodel.history.history['val_accuracy'],label = 'test accuracy')\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Percent Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot training and validation accuracy over epochs\n",
    "\n",
    "plt.plot(COVmodel.history.history['loss'], label = 'train loss')\n",
    "plt.plot(COVmodel.history.history['val_loss'],label = 'test_loss')\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Percent Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot training and validation loss over epochs\n",
    "\n",
    "y_pred = (COVmodel.predict(x_test) > 0.5).astype(int).flatten()\n",
    "# Predict on test set and threshold to get binary labels\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Compute confusion matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"COVID\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "# Display confusion matrix as a plot"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
